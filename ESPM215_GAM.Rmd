---
title: "ESPM 215 - Generalized Additive Models (GAMs)"
author: "Dorothy Chen, Kenzo Esquivel, Kane Russell, and Yvonne Socolar"
date: "2/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

- contrast GLM vs GAM graphs 
- explain single variable GAM output
- Exercise: try to visually choose optimal lambda parameter

```{r}
lambda <- ### try different values of lambda
ISIT16 <- filter(ISIT2, fStation == 16)
fit1 <- gam(Sources ~ s(Depth1000, sp = lambda), data = ISIT16)
depth_seq <- data.frame(Depth1000 = seq(min(ISIT16$Depth1000), max(ISIT16$Depth1000), length = 100))
pred <- predict.gam(fit1, depth_seq)

ggplot() + 
  geom_point(aes(Depth1000, Sources), ISIT16) + 
  geom_line(aes(depth_seq$Depth1000, pred), color = 'red')
```

- Create lambda vs. GCV graph to choose optimal lambda

```{r}
lambda <- ### try a range of lambda values
GCV <- 0

for (i in 1:length(lambda)) {
  gam_fit <- gam(Sources ~ s(Depth1000, sp = lambda[i]), data = ISIT16) 
  GCV[i] <- gam_fit$gcv.ubre
}

ggplot(data.frame(lambda, GCV)) +
  aes(lambda, GCV) + 
  geom_line()
```

- Compare with automatic GCV from model fit

```{r}
fit2 <- gam(Sources ~ s(Depth1000), data = ISIT16)
summary(fit2)

fit2$sp
fit2$gcv.ubre

```

- Incorporating random effects with Knape data (Kane)
    - Figure out difference between bs = "re" vs list....? (Kane & Dorothy)
- Discussion on paper?? (Kane & Dorothy)



## Potential datasets
```{r}
ISIT <- read.delim('ISIT.txt') # bioluminescence dataset (Zuur Ch. 3, 17)
RK <- read.delim('RoadKills.txt') # amphibian roadkills dataset (Zuur Ch. 16)
GF <- read.csv('jpe12720-sup-0003-apps2-greenfinch.csv')
GC <- read.csv('jpe12720-sup-0002-apps2-goldcrest.csv')
head(ISIT)
head(RK)
head(GF)
head(GC)
```

### Different packages for GAM processing. 

There are a number of different packages for GAM in R. 
  - the *gam* package was written by Hastie and Tibshirani (credited for introducing GAMs) and estimates the smoothing functions using a back-fitting algorithm (which allows for estimation of one smoother at a time)   \
  - the *mgcv* package, standing for "Mixed GAM Computation Vehicle with Automatic Smoothness Estimation", was introduced by Wood, and uses splines (which reduces function approximation error for a given dimension of smoothing basis). This package can handle large datasets, do cross validation, and allow for expansions into Generalized Additive Mixed Modeling (GAMM) frameworks. GAMM fitting relies on the nmle package, which is great for normally distributed models but not suitable for Poisson or Binomial GLMMs. A detailed walkthrough can be found at [this site](https://people.maths.bris.ac.uk/~sw15190/mgcv/tampere/mgcv.pdf)    \
  - the *gamm4* package, which is similar to the *mgcv* package but relies on the lme4 package for calculations (Fabian Scheipl trick)  \

```{r, echo = TRUE, message=FALSE, eval = F}
install.packages("gam")
install.packages("mgcv")
install.packages("gamm4")

```

```{r, echo = TRUE}
#library(gam)
library(mgcv)
#library(gamm4)
library(nlme)
library(tidyverse)

```

```{r}
ISIT$fMonth <- factor(ISIT$Month)
ISIT$fStation <- factor(ISIT$Station)
ISIT$fYear <- factor(ISIT$Year)
ISIT2 <- ISIT[ISIT$fStation != "4" &
              ISIT$fStation != "5" &
              ISIT$fStation != "10" ,]
ISIT2$Depth1000 <- ISIT2$SampleDepth/1000
head(ISIT2)
```

# Comparing GLMs to GAMs

```{r, echo = TRUE}

glmfit1 <- glm(Sources ~ fStation + Depth1000 + fMonth, 
               data = ISIT2, family = gaussian(link = "identity"))
par(mfrow = c(2, 2))
plot(glmfit1)
summary(glmfit1)

gamfit1 <- gam(Sources ~ fStation + s(Depth1000) + fMonth, 
               data = ISIT2)
par(mfrow = c(1, 1))
plot(gamfit1)
gam.check(gamfit1)
summary(gamfit1)
```


# Single value GAM fitting and talking about the R output 

$sources_{i} = \alpha + f(Depth_{i}) + factor(Station_{i}) + \epsilon_{i}$

$ \epsilon_{i} \sim N(0, \sigma^{2})$

## Show model fitting with different values of lambda

### INclude observed values on the fitted line 

=======

```{r}
gamfit1 <- gam(Sources ~ fStation + s(Depth1000) + fMonth, 
               data = ISIT2)
plot(gamfit1)
gam.check(gamfit1)
summary(gamfit1)
```

```{r}
gamfit2 <- mgcv::gam(Sources ~ s(fStation, bs = 're') + s(Depth1000) + fMonth, 
               data = ISIT2)
plot(gamfit2)
gam.check(gamfit2)
summary(gamfit2)
```

```{r}
gammfit3 <- gamm(Sources ~ s(Depth1000) + fMonth, 
                 random = list(fStation =~ 1), 
                 data = ISIT2)
plot(gammfit3$gam)
gam.check(gammfit3$gam)
summary(gammfit3$gam)
summary(gammfit3$lme)
```

```{r}
# gammfit4 <- gamm(Sources ~ s(Depth1000) + fMonth, 
#                  random = list(fStation =~ 1), 
#                  data = ISIT2, 
#                  weights = varComb(varIdent(form =~ 1 | fStation), 
#                                    varPower(form =~ Depth1000 | fStation)), 
#                  method = "REML", 
#                  control = lmeControl(niterEM = 5000, msMaxIter = 1000))
```

```{r}
AIC(gamfit1)
AIC(gamfit2)
AIC(gammfit3$lme)
```

```{r}
gamfit1$sp
gamfit1$gcv.ubre
```

```{r}
library(tidyverse)

lambda <- seq(0.0001, 0.002, by = 0.0001)
GCV <- 0

for (i in 1:length(lambda)) {
  gam_fit <- gam(Sources ~ fStation + fMonth + s(Depth1000, sp = lambda[i]), data = ISIT2) 
  GCV[i] <- gam_fit$gcv.ubre
}

table <- data.frame(lambda, GCV)
table

ggplot(data = table) +
  aes(x = lambda, y = GCV) + 
  geom_line()
```

```{r}
plot(gam(Sources ~ fStation + fMonth + s(Depth1000, sp = 0.00011), data = ISIT2))
plot(gam(Sources ~ fStation + fMonth + s(Depth1000, sp = 0.0011), data = ISIT2))
plot(gam(Sources ~ fStation + fMonth + s(Depth1000, sp = 1.1), data = ISIT2))
```


# More complex spline fitting and incorporating multiple variables with different smoothing techniques 









